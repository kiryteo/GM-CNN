# Config for ImplicitCNN

# Model
model:
  group: dihedral
  order: 14
  #group: cyclic
  #order: 28
  nbr: 2
  lr: 0.003
  dataset: mnist-bg-rot
  num_classes: 10 
  dropout: 0.3
  num_layers: 3
  out_channels: [48, 96, 160]

# Data
data:
  path: /localscratch/asa420/data/mnist_bg_rot/
  batch_size: 256 
  num_workers: 8

# Training
trainer:
  accelerator: gpu
  devices: 1 
  #strategy: ddp_find_unused_parameters_false
  max_epochs: 100
  #gradient_clip_val: 0.9
  log_every_n_steps: 10

tester:
  accelerator: gpu
  devices: 1
  num_nodes: 1

overfit:
  bs: 1

# Callbacks
#callbacks:
#  model_checkpoint:
#    _target_: pytorch_lightning.callbacks.ModelCheckpoint
#    monitor: val_accuracy
#    mode: max
#
#  lr_monitor:
#    _target_: pytorch_lightning.callbacks.LearningRateMonitor
#    logging_interval: step

# Logger
#logger:
#  wandb:
#    _target_: pytorch_lightning.loggers.WandbLogger
#    project: Partial_equivariance
#    log_model: gradients
