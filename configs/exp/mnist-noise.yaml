# Config for ImplicitCNN

# Model
model:
  group: cyclic
  order: 28 
  nbr: 3
  #err_idx: 391
  lr: 0.003
  dataset: mnist-noise
  num_classes: 10
  dropout: 0.3
  num_layers: 3
  out_channels: [48, 96, 160]

# Data
data:
  path: /localscratch/asa420/data/mnist_noise/mnist_noise_variations_all_1.amat
  batch_size: 128 
  num_workers: 8

# Training
trainer:
  accelerator: gpu
  devices: 1 
  #strategy: ddp_find_unused_parameters_false
  max_epochs: 20
  #gradient_clip_val: 0.9
  log_every_n_steps: 10

overfit:
  bs: 1

# Callbacks
#callbacks:
#  model_checkpoint:
#    _target_: pytorch_lightning.callbacks.ModelCheckpoint
#    monitor: val_accuracy
#    mode: max
#
#  lr_monitor:
#    _target_: pytorch_lightning.callbacks.LearningRateMonitor
#    logging_interval: step

# Logger
#logger:
#  wandb:
#    _target_: pytorch_lightning.loggers.WandbLogger
#    project: Partial_equivariance
#    log_model: gradients
