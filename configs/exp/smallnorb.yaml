# Config for ImplicitCNN

#dataset: smallnorb

# Model
model:
  group: cyclic
  order: 24
  nbr: 3
  #  err_idx: 287 
  lr: 0.003
  dataset: smallnorb
  num_classes: 4
  dropout: 0.3
  num_layers: 3
  out_channels: [48, 96, 160]
  #architecture:
  #  in_channels: [3, 32, 64]
  #  out_channels: [32, 64, 128]
  #  dropout: 0.5

# Data
data:
  batch_size: 256 
  num_workers: 8

# Training
trainer:
  accelerator: gpu
  devices: 1 
  #strategy: ddp_find_unused_parameters_false
  max_epochs: 120
  #gradient_clip_val: 0.9
  log_every_n_steps: 10

tester:
  accelerator: gpu
  devices: 1
  num_nodes: 1

overfit:
  bs: 1
# Callbacks
#callbacks:
#  model_checkpoint:
#    _target_: pytorch_lightning.callbacks.ModelCheckpoint
#    monitor: val_accuracy
#    mode: max
#
#  lr_monitor:
#    _target_: pytorch_lightning.callbacks.LearningRateMonitor
#    logging_interval: step

# Logger
#logger:
#  wandb:
#    _target_: pytorch_lightning.loggers.WandbLogger
#    project: Partial_equivariance
#    log_model: gradients
